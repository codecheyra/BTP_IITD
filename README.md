
# Fine-tuning Guide

To begin the fine-tuning process, follow the steps below.

## 1. Dataset Preparation

Start by running the `dataset_preparation` script, which will generate a `train.csv` file containing questions and answers in two respective columns for training purposes. To create this file, execute the entire `dataset_preparation.ipynb` file.

For creating a `test.csv` file that includes only questions without answers, run the `dataset_preparation` code only up to the point where questions are prepared, selecting random pages or specific sections from the sample PDF file. This approach allows for the generation of a `test.csv` that includes questions created from these randomly chosen or specific pages.

### Files Needed:
- **Sample PDF file**: Source PDF from which questions are generated.
- **train.csv**: Contains questions and answers for model training.
- **test.csv**: Contains only questions for model testing.

## 2. Model Selection

For optimal results, select models that are specifically tailored to your task. Open-source models suitable for fine-tuning are available on platforms like [Kaggle](https://www.kaggle.com/) and [Hugging Face](https://huggingface.co/).

For more insights into model performance across different question types, refer to the **Multiple Choice** folder, which provides datasets with questions and single-choice answers from four options.

## 3. Fine-tuning and Evaluation

After preparing your datasets:
1. Fine-tune the model using `train.csv`.
2. Evaluate the model’s performance using `test.csv`.

Upon evaluation, the model will generate a `submission.csv` file. This file contains the model’s output answers for each question in `test.csv`, with the answers listed in a separate column.

### Output File:
- **submission.csv**: Contains answers generated by the fine-tuned model for each question in `test.csv`.

## Important Notes

1. **Download the model** before starting the fine-tuning process.
2. Verify that **file paths** for inputs and outputs are correctly specified in the appropriate sections of your code.
3. Confirm that your Hugging Face **authentication tokens** are created and up-to-date.

Feel free to experiment with different models and configurations to gain a deeper understanding of model performance across various question-answer datasets.


If you are interested in exploring fine-tuning and model evaluation on different types of datasets, such as those with questions and single-choice answers among four options, you can refer to the **Multiple Choice** folder provided.
